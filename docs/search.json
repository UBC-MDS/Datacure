[
  {
    "objectID": "reference/validate_numeric_column.validate_numeric_column.html",
    "href": "reference/validate_numeric_column.validate_numeric_column.html",
    "title": "validate_numeric_column.validate_numeric_column",
    "section": "",
    "text": "validate_numeric_column.validate_numeric_column(\n    df,\n    column,\n    min_value=None,\n    max_value=None,\n    allow_negative=True,\n)\nValidate a numeric column against logical and domain-specific constraints.\nThis function performs diagnostic checks on a specified numeric column in a pandas DataFrame. It identifies values that fall outside an expected range or violate negative-value rules. The function does not modify the original DataFrame; instead, it returns a new DataFrame containing only the rows where violations occurred, along with a textual description of the issue found. This makes the function suitable for automated data validation pipelines, testing, and reporting.\n\n\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\ndf\npandas.DataFrame\nThe input DataFrame containing the numeric column to check.\nrequired\n\n\ncolumn\nstr\nThe name of the numeric column to be validated. The function will raise a KeyError if this column is not found in the DataFrame.\nrequired\n\n\nmin_value\nfloat\nThe minimum allowed value (inclusive). If provided, any value in the column that is strictly less than this threshold is considered a violation.\nNone\n\n\nmax_value\nfloat\nThe maximum allowed value (inclusive). If provided, any value in the column that is strictly greater than this threshold is considered a violation.\nNone\n\n\nallow_negative\nbool\nWhen set to False, any negative numeric value will be treated as a violation, regardless of the specified min_value.\nTrue\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\n\n\n\n\n\npandas.DataFrame\nA DataFrame containing all rows where at least one validation rule was broken. The returned DataFrame will contain all original columns plus an additional column named \"violation_reason\" describing the type of constraint that was violated. If the column contains no invalid values, an empty DataFrame is returned.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\n\n\n\n\n\nKeyError\nIf the specified column is not present in the input DataFrame.\n\n\n\nTypeError\nIf the specified column cannot be interpreted as numeric (e.g., contains non-numeric strings).\n\n\n\n\n\n\n&gt;&gt;&gt; violations = validate_numeric_column(\n...     df,\n...     column=\"age\",\n...     min_value=0,\n...     max_value=120,\n...     allow_negative=False\n... )\n&gt;&gt;&gt; violations.empty\nTrue\n\n\n\n\nThis function is purely diagnostic and performs no in-place modification.\nIt is designed to be simple to test using small DataFrames with known invalid values."
  },
  {
    "objectID": "reference/validate_numeric_column.validate_numeric_column.html#parameters",
    "href": "reference/validate_numeric_column.validate_numeric_column.html#parameters",
    "title": "validate_numeric_column.validate_numeric_column",
    "section": "",
    "text": "Name\nType\nDescription\nDefault\n\n\n\n\ndf\npandas.DataFrame\nThe input DataFrame containing the numeric column to check.\nrequired\n\n\ncolumn\nstr\nThe name of the numeric column to be validated. The function will raise a KeyError if this column is not found in the DataFrame.\nrequired\n\n\nmin_value\nfloat\nThe minimum allowed value (inclusive). If provided, any value in the column that is strictly less than this threshold is considered a violation.\nNone\n\n\nmax_value\nfloat\nThe maximum allowed value (inclusive). If provided, any value in the column that is strictly greater than this threshold is considered a violation.\nNone\n\n\nallow_negative\nbool\nWhen set to False, any negative numeric value will be treated as a violation, regardless of the specified min_value.\nTrue"
  },
  {
    "objectID": "reference/validate_numeric_column.validate_numeric_column.html#returns",
    "href": "reference/validate_numeric_column.validate_numeric_column.html#returns",
    "title": "validate_numeric_column.validate_numeric_column",
    "section": "",
    "text": "Name\nType\nDescription\n\n\n\n\n\npandas.DataFrame\nA DataFrame containing all rows where at least one validation rule was broken. The returned DataFrame will contain all original columns plus an additional column named \"violation_reason\" describing the type of constraint that was violated. If the column contains no invalid values, an empty DataFrame is returned."
  },
  {
    "objectID": "reference/validate_numeric_column.validate_numeric_column.html#raises",
    "href": "reference/validate_numeric_column.validate_numeric_column.html#raises",
    "title": "validate_numeric_column.validate_numeric_column",
    "section": "",
    "text": "Name\nType\nDescription\n\n\n\n\n\nKeyError\nIf the specified column is not present in the input DataFrame.\n\n\n\nTypeError\nIf the specified column cannot be interpreted as numeric (e.g., contains non-numeric strings)."
  },
  {
    "objectID": "reference/validate_numeric_column.validate_numeric_column.html#examples",
    "href": "reference/validate_numeric_column.validate_numeric_column.html#examples",
    "title": "validate_numeric_column.validate_numeric_column",
    "section": "",
    "text": "&gt;&gt;&gt; violations = validate_numeric_column(\n...     df,\n...     column=\"age\",\n...     min_value=0,\n...     max_value=120,\n...     allow_negative=False\n... )\n&gt;&gt;&gt; violations.empty\nTrue"
  },
  {
    "objectID": "reference/validate_numeric_column.validate_numeric_column.html#notes",
    "href": "reference/validate_numeric_column.validate_numeric_column.html#notes",
    "title": "validate_numeric_column.validate_numeric_column",
    "section": "",
    "text": "This function is purely diagnostic and performs no in-place modification.\nIt is designed to be simple to test using small DataFrames with known invalid values."
  },
  {
    "objectID": "reference/validate_categorical_schema.validate_categorical_schema.html",
    "href": "reference/validate_categorical_schema.validate_categorical_schema.html",
    "title": "validate_categorical_schema.validate_categorical_schema",
    "section": "",
    "text": "validate_categorical_schema.validate_categorical_schema(\n    df,\n    column,\n    allowed_categories,\n)\nValidate that a categorical column conforms to a predefined allowed-value schema.\nThis function checks whether all non-missing values in df[column] are contained in allowed_categories. Missing values (NaN/None) are ignored. Values not in allowed_categories are reported in invalid_records.\n\n\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\ndf\npandas.DataFrame\nThe DataFrame containing the categorical column.\nrequired\n\n\ncolumn\nstr\nName of the categorical column to validate.\nrequired\n\n\nallowed_categories\nSequence\nAn iterable of allowed category values (e.g., list, set, tuple).\nrequired\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\n\n\n\n\n\ndict\nA validation summary containing: - status: {‘pass’, ‘fail’} - invalid_records: pandas.DataFrame A DataFrame with columns [‘index’, ‘column’, ‘raw_value’]."
  },
  {
    "objectID": "reference/validate_categorical_schema.validate_categorical_schema.html#parameters",
    "href": "reference/validate_categorical_schema.validate_categorical_schema.html#parameters",
    "title": "validate_categorical_schema.validate_categorical_schema",
    "section": "",
    "text": "Name\nType\nDescription\nDefault\n\n\n\n\ndf\npandas.DataFrame\nThe DataFrame containing the categorical column.\nrequired\n\n\ncolumn\nstr\nName of the categorical column to validate.\nrequired\n\n\nallowed_categories\nSequence\nAn iterable of allowed category values (e.g., list, set, tuple).\nrequired"
  },
  {
    "objectID": "reference/validate_categorical_schema.validate_categorical_schema.html#returns",
    "href": "reference/validate_categorical_schema.validate_categorical_schema.html#returns",
    "title": "validate_categorical_schema.validate_categorical_schema",
    "section": "",
    "text": "Name\nType\nDescription\n\n\n\n\n\ndict\nA validation summary containing: - status: {‘pass’, ‘fail’} - invalid_records: pandas.DataFrame A DataFrame with columns [‘index’, ‘column’, ‘raw_value’]."
  },
  {
    "objectID": "reference/load_or_validate_source.load_or_validate_source.html",
    "href": "reference/load_or_validate_source.load_or_validate_source.html",
    "title": "load_or_validate_source.load_or_validate_source",
    "section": "",
    "text": "load_or_validate_source.load_or_validate_source(\n    dataframe=None,\n    source=None,\n    expected_min_cols=1,\n    sample_size=2048,\n)\nLoad a CSV from a path/URL or validate and clean a provided DataFrame.\n\n\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\ndataframe\nOptional[pd.DataFrame]\nAn already-loaded DataFrame to validate and clean.\nNone\n\n\nsource\nstr\nPath or URL to a CSV file. HTTP/HTTPS URLs and local filesystem paths are supported.\nNone\n\n\nexpected_min_cols\nint\nMinimum number of columns expected after loading (default: 2). Used to detect probable delimiter or corruption issues.\n1\n\n\nsample_size\nint\nNumber of characters to sample from the source when sniffing the delimiter and detecting basic corruption (default: 2048).\n2048\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\n\n\n\n\n\ntuple[pandas.DataFrame, ChangeReport]\ndf : pandas.DataFrame Cleaned and validated DataFrame. Cleaning includes normalizing column headers (strip, whitespace -&gt; underscore, replace illegal chars with underscores) and trimming string cells. report : ChangeReport Report of changes and metadata (detected delimiter, renamed columns mapping, counts of trimmed cells and illegal-char fixes, shape before/after).\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\n\n\n\n\n\nTypeError\nIf source is neither a string nor a pandas.DataFrame.\n\n\n\nDataLoadError\nOn I/O or parsing failures and validation errors, including: - unable to read/download source - inconsistent column counts in sample (possible corruption) - first row looks like data instead of header - pandas failed to parse CSV - resulting DataFrame is empty or has fewer than expected_min_cols\n\n\n\n\n\n\n\nDelimiter detection uses csv.Sniffer on a sample; falls back to ‘,’ on failure.\nWhen source is a DataFrame, it is copied and validated; no I/O is performed.\n\n\n\n\n&gt;&gt;&gt; df, rpt = load_or_validate_source(source=\"data.csv\")\n&gt;&gt;&gt; df, rpt = load_or_validate_source(dataframe=existing_df)"
  },
  {
    "objectID": "reference/load_or_validate_source.load_or_validate_source.html#parameters",
    "href": "reference/load_or_validate_source.load_or_validate_source.html#parameters",
    "title": "load_or_validate_source.load_or_validate_source",
    "section": "",
    "text": "Name\nType\nDescription\nDefault\n\n\n\n\ndataframe\nOptional[pd.DataFrame]\nAn already-loaded DataFrame to validate and clean.\nNone\n\n\nsource\nstr\nPath or URL to a CSV file. HTTP/HTTPS URLs and local filesystem paths are supported.\nNone\n\n\nexpected_min_cols\nint\nMinimum number of columns expected after loading (default: 2). Used to detect probable delimiter or corruption issues.\n1\n\n\nsample_size\nint\nNumber of characters to sample from the source when sniffing the delimiter and detecting basic corruption (default: 2048).\n2048"
  },
  {
    "objectID": "reference/load_or_validate_source.load_or_validate_source.html#returns",
    "href": "reference/load_or_validate_source.load_or_validate_source.html#returns",
    "title": "load_or_validate_source.load_or_validate_source",
    "section": "",
    "text": "Name\nType\nDescription\n\n\n\n\n\ntuple[pandas.DataFrame, ChangeReport]\ndf : pandas.DataFrame Cleaned and validated DataFrame. Cleaning includes normalizing column headers (strip, whitespace -&gt; underscore, replace illegal chars with underscores) and trimming string cells. report : ChangeReport Report of changes and metadata (detected delimiter, renamed columns mapping, counts of trimmed cells and illegal-char fixes, shape before/after)."
  },
  {
    "objectID": "reference/load_or_validate_source.load_or_validate_source.html#raises",
    "href": "reference/load_or_validate_source.load_or_validate_source.html#raises",
    "title": "load_or_validate_source.load_or_validate_source",
    "section": "",
    "text": "Name\nType\nDescription\n\n\n\n\n\nTypeError\nIf source is neither a string nor a pandas.DataFrame.\n\n\n\nDataLoadError\nOn I/O or parsing failures and validation errors, including: - unable to read/download source - inconsistent column counts in sample (possible corruption) - first row looks like data instead of header - pandas failed to parse CSV - resulting DataFrame is empty or has fewer than expected_min_cols"
  },
  {
    "objectID": "reference/load_or_validate_source.load_or_validate_source.html#notes",
    "href": "reference/load_or_validate_source.load_or_validate_source.html#notes",
    "title": "load_or_validate_source.load_or_validate_source",
    "section": "",
    "text": "Delimiter detection uses csv.Sniffer on a sample; falls back to ‘,’ on failure.\nWhen source is a DataFrame, it is copied and validated; no I/O is performed."
  },
  {
    "objectID": "reference/load_or_validate_source.load_or_validate_source.html#examples",
    "href": "reference/load_or_validate_source.load_or_validate_source.html#examples",
    "title": "load_or_validate_source.load_or_validate_source",
    "section": "",
    "text": "&gt;&gt;&gt; df, rpt = load_or_validate_source(source=\"data.csv\")\n&gt;&gt;&gt; df, rpt = load_or_validate_source(dataframe=existing_df)"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Welcome to Datacure",
    "section": "",
    "text": "Documentation\n\n\n\nCI/CD\n \n\n\nPackage\n \n\n\nMeta\n\n\n\n\nDatacure is a project designed to streamline data validation and cleaning process. It provides a multi-layered approach moving from high-level structural checks to granular value-level verification to achieve data integrity. By catching data errors early, it ensures the datasets is model-ready.\nTable Level Integrity\nRobustly load and clean tabular data from either a CSV file (via a local path or URL) or an existing pandas DataFrame. Evaluates the overall structure of the DataFrame to prevent downstream failures\n\nload_or_validate_source(df, source, expected_min_cols, sample_size)\n\nInput flexibility: Accepts either a CSV file (from a local path or URL) or an existing pandas DataFrame.\nAutomatic delimiter detection: For CSVs, detects the delimiter using a sample of the file and handles common formatting issues.\nCorruption checks: Identifies inconsistencies such as mismatched column counts and ensures the first row is a proper header rather than data.\nColumn header cleaning: Strips leading and trailing whitespace, replaces internal spaces with underscores, substitutes illegal characters with underscores.\nData cleaning: Trims leading and trailing whitespace from all string values in the table.\nChange reporting: Returns a ChangeReport object summarizing all modifications made during loading and cleaning.\n\n\nCategorical and Datetime Validation\nEvaluates whether categorical and datetime columns in a DataFrame conform to predefined schemas to prevent errors in analysis and modeling.\n\nvalidate_categorical_schema(df, column, allowed_categories)\n\nChecks whether all non-missing values in a categorical column belong to a predefined set of allowed categories.\nIdentifies and reports invalid category values at the row level.\nReturns a pass/fail validation status along with a structured table of invalid records.\n\nvalidate_datetime_schema(df, columns, datetime_format, coerce_invalid=False)\n\nChecks whether datetime columns conform to a specified datetime format.\nIdentifies and reports invalid datetime values at the row level.\nOptionally (coerce_invalid=True) returns a copy of the DataFrame where valid values are converted to specified datetime type.\n\n\nNumeric EDA Plotting\nProvides a set of exploratory data analysis (EDA) focused on numeric columns. These functions will assist in quickly assessing distribution shapes, detect outliers and evaluate correlations\n\nplot_numeric_distributions(df)\n\nGenerates histogram‑based distribution plots for all numeric columns.\nHelps identify skewness, modality, and potential outliers across variables.\n\n\nNumeric value checks\nNumeric value checks ensure that numerical columns contain valid and meaningful values. These checks help detect outliers, impossible values, and violations of constraints that should logically apply to the data. - validate_numeric_column(df, column, min_value,max_value,allow_negative) - Verifys that numeric values fall within an expected range. - Detects negative values where they are not allowed - Identifies values that violate domain-specific boundaries.\nWhile standard libraries like Pandas provide tools to transform data, Datacure provides the rules to validate it. By focusing on data cleaning - structural integrity, column consistency, and value range constraints - it allows developers to build more resilient data pipelines with less boilerplate code.\n\n\nInstall the package form Test PyPI running the below command in your terminal:\npip install -i https://test.pypi.org/simple/ datacure\n\n\n\n\nClone the repository to your local machine by opening your terminal and run the following commands:\n\ngit clone https://github.com/UBC-MDS/DSCI_524_group20_datacure.git\ncd DSCI_524_group20_datacure\n\nCreate the conda environment from environment.yml:\n\nconda env create -f environment.yml\n\nActivate the environment:\n\nconda activate dsci_524_proj_env \n\n\n\nYou can install this package into your preferred Python environment using pip:\npip install -e .\n\n\n\nYou can run tests to validate all functions in the package using pytest:\npytest -v\n-v provides a verbose output showing the names of all tests and if they passed or not.\n\n\n\n\n\nThis option installs all required documentation dependencies automatically and builds the documentation:\nhatch run docs:build\n\n\n\nIf not already installed, you can install quarto from link. To generate the API reference pages and preview the documentation website run:\nquartodoc build --watch\nquarto preview\n\n\n\n\nimport pandas as pd\nfrom datacure import validate_datetime_schema\n\ndf = pd.DataFrame({\n    \"program\": [\"academic\", \"general\", \"unknown\"],\n    \"start_date\": [\"2023-01-01\", \"2023-02-01\", \"01-03-2023\"]\n})\n\n# Validate datetime format\nresult = validate_datetime_schema(\n    df,\n    columns=[\"start_date\"],\n    datetime_format=\"%Y-%m-%d\"\n)\n\n\n\n\nJose Davila\nSsemakula Peter Wasswa\nYanxin Liang\nShruti Sasi\n\n\n\n\n\nCopyright © 2026 Jose Davila , Ssemakula Peter Wasswa , Yanxin Liang , Shruti Sasi.\nFree software distributed under the MIT License."
  },
  {
    "objectID": "CONTRIBUTING.html",
    "href": "CONTRIBUTING.html",
    "title": "Contributing",
    "section": "",
    "text": "Contributions of all kinds are welcome here, and they are greatly appreciated! Every little bit helps, and credit will always be given.\n\n\nYou can contribute in many ways, for example:\n\nReport bugs\nFix Bugs\nImplement Features\nWrite Documentation\nSubmit Feedback\n\n\n\nReport bugs at https://github.com/UBC-MDS/datacure/issues.\nIf you are reporting a bug, please follow the template guidelines. The more detailed your report, the easier and thus faster we can help you.\n\n\n\nLook through the GitHub issues for bugs. Anything labelled with bug and help wanted is open to whoever wants to implement it. When you decide to work on such an issue, please assign yourself to it and add a comment that you’ll be working on that, too. If you see another issue without the help wanted label, just post a comment, the maintainers are usually happy for any support that they can get.\n\n\n\nLook through the GitHub issues for features. Anything labelled with enhancement and help wanted is open to whoever wants to implement it. As for fixing bugs, please assign yourself to the issue and add a comment that you’ll be working on that, too. If another enhancement catches your fancy, but it doesn’t have the help wanted label, just post a comment, the maintainers are usually happy for any support that they can get.\n\n\n\nDatacure could always use more documentation, whether as part of the official documentation, in docstrings, or even on the web in blog posts, articles, and such. Just open an issue to let us know what you will be working on so that we can provide you with guidance.\n\n\n\nThe best way to send feedback is to file an issue at https://github.com/UBC-MDS/datacure/issues. If your feedback fits the format of one of the issue templates, please use that. Remember that this is a volunteer-driven project and everybody has limited time.\n\n\n\n\nReady to contribute? Here’s how to set up Datacure for local development.\n\nFork the https://github.com/UBC-MDS/datacure repository on GitHub.\nClone your fork locally (if you want to work locally)\ngit clone git@github.com:your_name_here/datacure.git\nInstall hatch.\nCreate a branch for local development using the default branch (typically main) as a starting point. Use fix or feat as a prefix for your branch name.\ngit checkout main\ngit checkout -b fix-name-of-your-bugfix\nNow you can make your changes locally.\nWhen you’re done making changes, apply the quality assurance tools and check that your changes pass our test suite. This is all included with tox\nhatch run test:run\nCommit your changes and push your branch to GitHub. Please use semantic commit messages.\ngit add .\ngit commit -m \"fix: summarize your changes\"\ngit push -u origin fix-name-of-your-bugfix\nOpen the link displayed in the message when pushing your new branch in order to submit a pull request.\n\n\n\nBefore you submit a pull request, check that it meets these guidelines:\n\nThe pull request should include tests.\nIf the pull request adds functionality, the docs should be updated. Put your new functionality into a function with a docstring.\nYour pull request will automatically be checked by the full test suite. It needs to pass all of them before it can be considered for merging."
  },
  {
    "objectID": "CONTRIBUTING.html#example-contributions",
    "href": "CONTRIBUTING.html#example-contributions",
    "title": "Contributing",
    "section": "",
    "text": "You can contribute in many ways, for example:\n\nReport bugs\nFix Bugs\nImplement Features\nWrite Documentation\nSubmit Feedback\n\n\n\nReport bugs at https://github.com/UBC-MDS/datacure/issues.\nIf you are reporting a bug, please follow the template guidelines. The more detailed your report, the easier and thus faster we can help you.\n\n\n\nLook through the GitHub issues for bugs. Anything labelled with bug and help wanted is open to whoever wants to implement it. When you decide to work on such an issue, please assign yourself to it and add a comment that you’ll be working on that, too. If you see another issue without the help wanted label, just post a comment, the maintainers are usually happy for any support that they can get.\n\n\n\nLook through the GitHub issues for features. Anything labelled with enhancement and help wanted is open to whoever wants to implement it. As for fixing bugs, please assign yourself to the issue and add a comment that you’ll be working on that, too. If another enhancement catches your fancy, but it doesn’t have the help wanted label, just post a comment, the maintainers are usually happy for any support that they can get.\n\n\n\nDatacure could always use more documentation, whether as part of the official documentation, in docstrings, or even on the web in blog posts, articles, and such. Just open an issue to let us know what you will be working on so that we can provide you with guidance.\n\n\n\nThe best way to send feedback is to file an issue at https://github.com/UBC-MDS/datacure/issues. If your feedback fits the format of one of the issue templates, please use that. Remember that this is a volunteer-driven project and everybody has limited time."
  },
  {
    "objectID": "CONTRIBUTING.html#get-started",
    "href": "CONTRIBUTING.html#get-started",
    "title": "Contributing",
    "section": "",
    "text": "Ready to contribute? Here’s how to set up Datacure for local development.\n\nFork the https://github.com/UBC-MDS/datacure repository on GitHub.\nClone your fork locally (if you want to work locally)\ngit clone git@github.com:your_name_here/datacure.git\nInstall hatch.\nCreate a branch for local development using the default branch (typically main) as a starting point. Use fix or feat as a prefix for your branch name.\ngit checkout main\ngit checkout -b fix-name-of-your-bugfix\nNow you can make your changes locally.\nWhen you’re done making changes, apply the quality assurance tools and check that your changes pass our test suite. This is all included with tox\nhatch run test:run\nCommit your changes and push your branch to GitHub. Please use semantic commit messages.\ngit add .\ngit commit -m \"fix: summarize your changes\"\ngit push -u origin fix-name-of-your-bugfix\nOpen the link displayed in the message when pushing your new branch in order to submit a pull request.\n\n\n\nBefore you submit a pull request, check that it meets these guidelines:\n\nThe pull request should include tests.\nIf the pull request adds functionality, the docs should be updated. Put your new functionality into a function with a docstring.\nYour pull request will automatically be checked by the full test suite. It needs to pass all of them before it can be considered for merging."
  },
  {
    "objectID": "CHANGELOG.html",
    "href": "CHANGELOG.html",
    "title": "Changelog",
    "section": "",
    "text": "All notable changes to this project will be documented in this file.\nThe format is based on Keep a Changelog, and this project adheres to Semantic Versioning.\n\n\n\nUpcoming features and fixes\n\n\n\n\n\nFirst release"
  },
  {
    "objectID": "CHANGELOG.html#unreleased",
    "href": "CHANGELOG.html#unreleased",
    "title": "Changelog",
    "section": "",
    "text": "Upcoming features and fixes"
  },
  {
    "objectID": "CHANGELOG.html#section",
    "href": "CHANGELOG.html#section",
    "title": "Changelog",
    "section": "",
    "text": "First release"
  },
  {
    "objectID": "CODE_OF_CONDUCT.html",
    "href": "CODE_OF_CONDUCT.html",
    "title": "Contributor Covenant Code of Conduct",
    "section": "",
    "text": "We as members, contributors, and leaders pledge to make participation in our community a harassment-free experience for everyone, regardless of age, body size, visible or invisible disability, ethnicity, sex characteristics, gender identity and expression, level of experience, education, socio-economic status, nationality, personal appearance, race, religion, or sexual identity and orientation.\nWe pledge to act and interact in ways that contribute to an open, welcoming, diverse, inclusive, and healthy community.\n\n\n\nExamples of behavior that contributes to a positive environment for our community include:\n\nDemonstrating empathy and kindness toward other people\nBeing respectful of differing opinions, viewpoints, and experiences\nGiving and gracefully accepting constructive feedback\nAccepting responsibility and apologizing to those affected by our mistakes, and learning from the experience\nFocusing on what is best not just for us as individuals, but for the overall community\n\nExamples of unacceptable behavior include:\n\nThe use of sexualized language or imagery, and sexual attention or advances of any kind\nTrolling, insulting or derogatory comments, and personal or political attacks\nPublic or private harassment\nPublishing others’ private information, such as a physical or email address, without their explicit permission\nOther conduct which could reasonably be considered inappropriate in a professional setting\n\n\n\n\nCommunity leaders are responsible for clarifying and enforcing our standards of acceptable behavior and will take appropriate and fair corrective action in response to any behavior that they deem inappropriate, threatening, offensive, or harmful.\nCommunity leaders have the right and responsibility to remove, edit, or reject comments, commits, code, wiki edits, issues, and other contributions that are not aligned to this Code of Conduct, and will communicate reasons for moderation decisions when appropriate.\n\n\n\nThis Code of Conduct applies within all community spaces, and also applies when an individual is officially representing the community in public spaces. Examples of representing our community include using an official e-mail address, posting via an official social media account, or acting as an appointed representative at an online or offline event.\n\n\n\nInstances of abusive, harassing, or otherwise unacceptable behavior may be reported to the community leaders responsible for enforcement at [INSERT CONTACT METHOD]. All complaints will be reviewed and investigated promptly and fairly.\nAll community leaders are obligated to respect the privacy and security of the reporter of any incident.\n\n\n\nCommunity leaders will follow these Community Impact Guidelines in determining the consequences for any action they deem in violation of this Code of Conduct:\n\n\nCommunity Impact: Use of inappropriate language or other behavior deemed unprofessional or unwelcome in the community.\nConsequence: A private, written warning from community leaders, providing clarity around the nature of the violation and an explanation of why the behavior was inappropriate. A public apology may be requested.\n\n\n\nCommunity Impact: A violation through a single incident or series of actions.\nConsequence: A warning with consequences for continued behavior. No interaction with the people involved, including unsolicited interaction with those enforcing the Code of Conduct, for a specified period of time. This includes avoiding interactions in community spaces as well as external channels like social media. Violating these terms may lead to a temporary or permanent ban.\n\n\n\nCommunity Impact: A serious violation of community standards, including sustained inappropriate behavior.\nConsequence: A temporary ban from any sort of interaction or public communication with the community for a specified period of time. No public or private interaction with the people involved, including unsolicited interaction with those enforcing the Code of Conduct, is allowed during this period. Violating these terms may lead to a permanent ban.\n\n\n\nCommunity Impact: Demonstrating a pattern of violation of community standards, including sustained inappropriate behavior, harassment of an individual, or aggression toward or disparagement of classes of individuals.\nConsequence: A permanent ban from any sort of public interaction within the community.\n\n\n\n\nThis Code of Conduct is adapted from the Contributor Covenant, version 2.0, available at https://www.contributor-covenant.org/version/2/0/code_of_conduct.html.\nCommunity Impact Guidelines were inspired by Mozilla’s code of conduct enforcement ladder.\nFor answers to common questions about this code of conduct, see the FAQ at https://www.contributor-covenant.org/faq. Translations are available at https://www.contributor-covenant.org/translations."
  },
  {
    "objectID": "CODE_OF_CONDUCT.html#our-pledge",
    "href": "CODE_OF_CONDUCT.html#our-pledge",
    "title": "Contributor Covenant Code of Conduct",
    "section": "",
    "text": "We as members, contributors, and leaders pledge to make participation in our community a harassment-free experience for everyone, regardless of age, body size, visible or invisible disability, ethnicity, sex characteristics, gender identity and expression, level of experience, education, socio-economic status, nationality, personal appearance, race, religion, or sexual identity and orientation.\nWe pledge to act and interact in ways that contribute to an open, welcoming, diverse, inclusive, and healthy community."
  },
  {
    "objectID": "CODE_OF_CONDUCT.html#our-standards",
    "href": "CODE_OF_CONDUCT.html#our-standards",
    "title": "Contributor Covenant Code of Conduct",
    "section": "",
    "text": "Examples of behavior that contributes to a positive environment for our community include:\n\nDemonstrating empathy and kindness toward other people\nBeing respectful of differing opinions, viewpoints, and experiences\nGiving and gracefully accepting constructive feedback\nAccepting responsibility and apologizing to those affected by our mistakes, and learning from the experience\nFocusing on what is best not just for us as individuals, but for the overall community\n\nExamples of unacceptable behavior include:\n\nThe use of sexualized language or imagery, and sexual attention or advances of any kind\nTrolling, insulting or derogatory comments, and personal or political attacks\nPublic or private harassment\nPublishing others’ private information, such as a physical or email address, without their explicit permission\nOther conduct which could reasonably be considered inappropriate in a professional setting"
  },
  {
    "objectID": "CODE_OF_CONDUCT.html#enforcement-responsibilities",
    "href": "CODE_OF_CONDUCT.html#enforcement-responsibilities",
    "title": "Contributor Covenant Code of Conduct",
    "section": "",
    "text": "Community leaders are responsible for clarifying and enforcing our standards of acceptable behavior and will take appropriate and fair corrective action in response to any behavior that they deem inappropriate, threatening, offensive, or harmful.\nCommunity leaders have the right and responsibility to remove, edit, or reject comments, commits, code, wiki edits, issues, and other contributions that are not aligned to this Code of Conduct, and will communicate reasons for moderation decisions when appropriate."
  },
  {
    "objectID": "CODE_OF_CONDUCT.html#scope",
    "href": "CODE_OF_CONDUCT.html#scope",
    "title": "Contributor Covenant Code of Conduct",
    "section": "",
    "text": "This Code of Conduct applies within all community spaces, and also applies when an individual is officially representing the community in public spaces. Examples of representing our community include using an official e-mail address, posting via an official social media account, or acting as an appointed representative at an online or offline event."
  },
  {
    "objectID": "CODE_OF_CONDUCT.html#enforcement",
    "href": "CODE_OF_CONDUCT.html#enforcement",
    "title": "Contributor Covenant Code of Conduct",
    "section": "",
    "text": "Instances of abusive, harassing, or otherwise unacceptable behavior may be reported to the community leaders responsible for enforcement at [INSERT CONTACT METHOD]. All complaints will be reviewed and investigated promptly and fairly.\nAll community leaders are obligated to respect the privacy and security of the reporter of any incident."
  },
  {
    "objectID": "CODE_OF_CONDUCT.html#enforcement-guidelines",
    "href": "CODE_OF_CONDUCT.html#enforcement-guidelines",
    "title": "Contributor Covenant Code of Conduct",
    "section": "",
    "text": "Community leaders will follow these Community Impact Guidelines in determining the consequences for any action they deem in violation of this Code of Conduct:\n\n\nCommunity Impact: Use of inappropriate language or other behavior deemed unprofessional or unwelcome in the community.\nConsequence: A private, written warning from community leaders, providing clarity around the nature of the violation and an explanation of why the behavior was inappropriate. A public apology may be requested.\n\n\n\nCommunity Impact: A violation through a single incident or series of actions.\nConsequence: A warning with consequences for continued behavior. No interaction with the people involved, including unsolicited interaction with those enforcing the Code of Conduct, for a specified period of time. This includes avoiding interactions in community spaces as well as external channels like social media. Violating these terms may lead to a temporary or permanent ban.\n\n\n\nCommunity Impact: A serious violation of community standards, including sustained inappropriate behavior.\nConsequence: A temporary ban from any sort of interaction or public communication with the community for a specified period of time. No public or private interaction with the people involved, including unsolicited interaction with those enforcing the Code of Conduct, is allowed during this period. Violating these terms may lead to a permanent ban.\n\n\n\nCommunity Impact: Demonstrating a pattern of violation of community standards, including sustained inappropriate behavior, harassment of an individual, or aggression toward or disparagement of classes of individuals.\nConsequence: A permanent ban from any sort of public interaction within the community."
  },
  {
    "objectID": "CODE_OF_CONDUCT.html#attribution",
    "href": "CODE_OF_CONDUCT.html#attribution",
    "title": "Contributor Covenant Code of Conduct",
    "section": "",
    "text": "This Code of Conduct is adapted from the Contributor Covenant, version 2.0, available at https://www.contributor-covenant.org/version/2/0/code_of_conduct.html.\nCommunity Impact Guidelines were inspired by Mozilla’s code of conduct enforcement ladder.\nFor answers to common questions about this code of conduct, see the FAQ at https://www.contributor-covenant.org/faq. Translations are available at https://www.contributor-covenant.org/translations."
  },
  {
    "objectID": "DEVELOPMENT.html",
    "href": "DEVELOPMENT.html",
    "title": "Development Guide",
    "section": "",
    "text": "Welcome to your shiny new package. This page will help you get started with using Hatch to manage your package.\nIf you look at your project, you will see that a pyproject.toml file. This file stores both your package configuration and settings for development tools like Hatch that you will use to work on your package.\nThis file is written using a .toml format. You can learn more about toml here. Here’s the TL&DR:\n\nEach [] section in the toml file is called a table.\nYou can nest tables with double brackets like this[[]]\nTables contain information about a element that you want to configure.\n\nWe are using Hatch as the default packaging tool. Hatch allows you to configure and run environments and scripts similar to workflow tools like tox or nox.\nHach, by default, uses virtual environments (venv) to manage environments. But you can configure it to use other environment tools.Read the hatch documentation to learn more about environments.\nFor this template, we have set up Hatch environments for you to use. At the bottom of your pyproject.toml file, notice a hatch environment section that looks like this:\n########################################\n# Hatch Environments\n########################################\nBelow is the Hatch environment to install your package. Notice that it defines pip and twine as two packages that the environment needs.\n[tool.hatch.envs.build]\ndescription = \"\"\"Test the installation the package.\"\"\"\ndependencies = [\n    \"pip\",\n    \"twine\",\n]\nThe table below defines the scripts that you will run build and check your package.\n[tool.hatch.envs.build.scripts]\ncheck = [\n    \"pip check\",\n    \"hatch build {args:--clean}\",\n    \"twine check dist/*\",\n]\ndetached = true\nYou can enter that environment to check it out:\n$ hatch shell build\nIf you run pip list, in the environment, twine will be there:\n$ pip list\nHatch by default, installs your package in editable mode (-e) into its virtual environments. But if detached=True is set, then it will skip installing your package into the virtual enviornment.\n\n\nBelow you see the Hatch environment test table.\ntool.hatch.envs says, “Hey, Hatch, this is the definition for an environment.” test is the name of the environment.\nThe environment below defines the dependencies that Hatch needs to install into the environment named test.\n[tool.hatch.envs.test]\ndescription = \"\"\"Run the test suite.\"\"\"\ndependencies = [\n    \"pytest\",\n    \"pytest-cov\",\n    \"pytest-raises\",\n    \"pytest-randomly\",\n    \"pytest-xdist\",\n]\nTo enter a Hatch environment use:\nhatch shell environmentname\nSo you can enter the test environment above with:\nhatch shell test\n\n\n\nIf the environment has a matrix associated with it, that tells Hatch to run the test scripts across different Python versions.\n[[tool.hatch.envs.test.matrix]]\npython = [\"3.10\", \"3.11\", \"3.12\", \"3.13\"]\nIf you run hatch shell test, you will see the output below. To enter an environment with a matrix attached to it, you need to pick the Python environment version that you want to open.\n$ hatch shell test                           \nEnvironment `test` defines a matrix, choose one of the following instead:\n\ntest.py3.10\ntest.py3.11\ntest.py3.12\ntest.py3.13\nOpen the Python 3.13 environment like this:\n$ hatch shell test.py3.13\nTo leave an environment use:\n$ deactivate\n\n\n\nIn the tests section of your pyproject.toml, you will see a tool.hatch.envs.test.scripts table.\nThis table defines the commands that you want Hatch to run in the test environment. Notice that the script has one command called run.\n[tool.hatch.envs.test.scripts]\nrun = \"pytest {args:--cov=greatproject --cov-report=term-missing}\"\nTo run this script , use:\nhatch run test:run\n\nhatch run: calls Hatch and tells it that it will be running a command\ntest:run: defines the environment you want it to run (test) and defines the name of the “script” to berun.\n\nIf you have a Hatch matrix setup for tests, it will both install the necessary Python version using UV and run your tests on each version of the Python versions that you declare in the matrix table. In this case, there are 4 Python versions in the environment, so your tests will run 4 times, once in each Python version listed in the matrix table.\n@lwasser ➜ /workspaces/pyopensci-scipy25-create-python-package (main) $ hatch run test:run\n──────────────────────────────────────────────────────────────────────── test.py3.10 ────────────────────────────────────────────────────────────────────────\n==================================================================== test session starts ====================================================================\nplatform linux -- Python 3.10.16, pytest-8.4.1, pluggy-1.6.0\nUsing --randomly-seed=1490740387\nrootdir: /workspaces/pyopensci-scipy25-create-python-package\nconfigfile: pyproject.toml\ntestpaths: tests\nplugins: xdist-3.8.0, randomly-3.16.0, raises-0.11, cov-6.2.1\ncollected 2 items                                                                                                                                           \n\ntests/system/test_import.py .                                                                                                                         [ 50%]\ntests/unit/test_example.py .                                                                                                                          [100%]\n\n====================================================================== tests coverage =======================================================================\n_____________________________________________________ coverage: platform linux, python 3.10.16-final-0 ______________________________________________________\n\nName                           Stmts   Miss Branch BrPart    Cover   Missing\n----------------------------------------------------------------------------\nsrc/greatproject/__init__.py       0      0      0      0  100.00%\nsrc/greatproject/example.py        2      0      0      0  100.00%\n----------------------------------------------------------------------------\nTOTAL                              2      0      0      0  100.00%\n===================================================================== 2 passed in 0.05s =====================================================================\n──────────────────────────────────────────────────────────────────────── test.py3.11 ────────────────────────────────────────────────────────────────────────\n==================================================================== test session starts ====================================================================\nplatform linux -- Python 3.11.12, pytest-8.4.1, pluggy-1.6.0\nUsing --randomly-seed=1596865075\nrootdir: /workspaces/pyopensci-scipy25-create-python-package\nconfigfile: pyproject.toml\ntestpaths: tests\nplugins: xdist-3.8.0, randomly-3.16.0, raises-0.11, cov-6.2.1\ncollected 2 items                                                                                                                                           \n\ntests/system/test_import.py .                                                                                                                         [ 50%]\ntests/unit/test_example.py .                                                                                                                          [100%]\n\n====================================================================== tests coverage =======================================================================\n_____________________________________________________ coverage: platform linux, python 3.11.12-final-0 ______________________________________________________\n\nName                           Stmts   Miss Branch BrPart    Cover   Missing\n----------------------------------------------------------------------------\nsrc/greatproject/__init__.py       0      0      0      0  100.00%\nsrc/greatproject/example.py        2      0      0      0  100.00%\n----------------------------------------------------------------------------\nTOTAL                              2      0      0      0  100.00%\n===================================================================== 2 passed in 0.05s =====================================================================\n\n\n\nYou can build your package using the environment and scripts defined in the build tables:\nhatch run build:check\nThis script builds and checks the output distribution files of your package.\nThis build environment table declares that pip and twine should be added to that environment. Adding pip to the environment ensures that it is a current, up-to-date version.\n[tool.hatch.envs.build]\ndescription = \"\"\"Build and test your package.\"\"\"\ndependencies = [\n    \"pip\",\n    \"twine\",\n]\ndetached = true\n# This table installs created the command hatch run install:check which will build and check your package.\n[tool.hatch.envs.install.scripts]\ncheck = [\n    \"pip check\",\n    \"hatch build {args:--clean}\",\n    \"twine check dist/*\",\n]\nThis uses the above environment and tells hatch to run\n\npip check, # verifies your dependencies\nhatch build --clean\n\ntwine check dist/* # this checks your distribution for metadata and other potential issues. to build and test your package."
  },
  {
    "objectID": "DEVELOPMENT.html#build-your-package",
    "href": "DEVELOPMENT.html#build-your-package",
    "title": "Development Guide",
    "section": "",
    "text": "You can build your package using the environment and scripts defined in the build tables:\nhatch run build:check\nThis script builds and checks the output distribution files of your package.\nThis build environment table declares that pip and twine should be added to that environment. Adding pip to the environment ensures that it is a current, up-to-date version.\n[tool.hatch.envs.build]\ndescription = \"\"\"Build and test your package.\"\"\"\ndependencies = [\n    \"pip\",\n    \"twine\",\n]\ndetached = true\n# This table installs created the command hatch run install:check which will build and check your package.\n[tool.hatch.envs.install.scripts]\ncheck = [\n    \"pip check\",\n    \"hatch build {args:--clean}\",\n    \"twine check dist/*\",\n]\nThis uses the above environment and tells hatch to run\n\npip check, # verifies your dependencies\nhatch build --clean\n\ntwine check dist/* # this checks your distribution for metadata and other potential issues. to build and test your package."
  },
  {
    "objectID": "reference/index.html",
    "href": "reference/index.html",
    "title": "Function reference",
    "section": "",
    "text": "Functions to help you with data validation, data cleaning and plotting.\n\n\n\nload_or_validate_source.load_or_validate_source\nLoad a CSV from a path/URL or validate and clean a provided DataFrame.\n\n\nvalidate_categorical_schema.validate_categorical_schema\nValidate that a categorical column conforms to a predefined allowed-value schema.\n\n\nvalidate_datetime_schema.validate_datetime_schema\nValidate that specified columns follow a given datetime format.\n\n\nvalidate_numeric_column.validate_numeric_column\nValidate a numeric column against logical and domain-specific constraints.\n\n\nplots.plot_numeric_distributions\nPlot distribution histograms for all numeric columns."
  },
  {
    "objectID": "reference/index.html#datacure-functions",
    "href": "reference/index.html#datacure-functions",
    "title": "Function reference",
    "section": "",
    "text": "Functions to help you with data validation, data cleaning and plotting.\n\n\n\nload_or_validate_source.load_or_validate_source\nLoad a CSV from a path/URL or validate and clean a provided DataFrame.\n\n\nvalidate_categorical_schema.validate_categorical_schema\nValidate that a categorical column conforms to a predefined allowed-value schema.\n\n\nvalidate_datetime_schema.validate_datetime_schema\nValidate that specified columns follow a given datetime format.\n\n\nvalidate_numeric_column.validate_numeric_column\nValidate a numeric column against logical and domain-specific constraints.\n\n\nplots.plot_numeric_distributions\nPlot distribution histograms for all numeric columns."
  },
  {
    "objectID": "reference/plots.plot_numeric_distributions.html",
    "href": "reference/plots.plot_numeric_distributions.html",
    "title": "plots.plot_numeric_distributions",
    "section": "",
    "text": "plots.plot_numeric_distributions(df)\nPlot distribution histograms for all numeric columns.\nGenerates a grid of histogram plots to help visualize the distribution, skewness, and potential outliers in each numeric column. This function is intended as a exploratory tool for understanding the shape of the data.\n\n\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\ndf\npandas.DataFrame\nThe input dataset containing numeric columns.\nrequired\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\n\n\n\n\n\nNone\nDisplays histogram plots for each numeric column."
  },
  {
    "objectID": "reference/plots.plot_numeric_distributions.html#parameters",
    "href": "reference/plots.plot_numeric_distributions.html#parameters",
    "title": "plots.plot_numeric_distributions",
    "section": "",
    "text": "Name\nType\nDescription\nDefault\n\n\n\n\ndf\npandas.DataFrame\nThe input dataset containing numeric columns.\nrequired"
  },
  {
    "objectID": "reference/plots.plot_numeric_distributions.html#returns",
    "href": "reference/plots.plot_numeric_distributions.html#returns",
    "title": "plots.plot_numeric_distributions",
    "section": "",
    "text": "Name\nType\nDescription\n\n\n\n\n\nNone\nDisplays histogram plots for each numeric column."
  },
  {
    "objectID": "reference/validate_datetime_schema.validate_datetime_schema.html",
    "href": "reference/validate_datetime_schema.validate_datetime_schema.html",
    "title": "validate_datetime_schema.validate_datetime_schema",
    "section": "",
    "text": "validate_datetime_schema.validate_datetime_schema(\n    df,\n    columns,\n    datetime_format,\n    coerce_invalid=False,\n)\nValidate that specified columns follow a given datetime format.\nThis function validates each non-missing value in the specified columns by attempting to parse it using pd.to_datetime(..., format=datetime_format). Values that cannot be parsed under the provided format are recorded as invalid.\nBy default, the function performs validation only and does not modify the input data. When coerce_invalid=True, it returns a copy of the DataFrame where valid values are converted to pandas datetime dtype and invalid values are set to NaT.\n\n\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\ndf\npandas.DataFrame\nThe DataFrame containing the datetime column(s) to validate.\nrequired\n\n\ncolumns\nlist of str\nA list of datetime column names to validate. If any specified column is not present in df, a KeyError is raised.\nrequired\n\n\ndatetime_format\nstr\nExpected datetime format string used for strict validation (e.g., ‘%Y-%m-%d’).\nrequired\n\n\ncoerce_invalid\nbool\nWhether to return a coerced copy of the DataFrame. - If False, only validation is performed and the data are not modified. - If True, valid values are converted to datetime and invalid values are set to NaT in the returned validated_df.\nFalse\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\n\n\n\n\n\ndict\nA validation summary containing: - status : {‘pass’, ‘fail’} Overall validation status across all specified columns. 'pass' indicates that no invalid values were detected; 'fail' indicates that at least one invalid value was found. - validated_df : pandas.DataFrame A copy of the input DataFrame. If coerce_invalid=True, the specified datetime columns are converted to pandas datetime dtype (with invalid values set to NaT). - invalid_records : pandas.DataFrame A tidy DataFrame listing all invalid datetime values with columns: - index : index labels from df.index where validation failed - column : name of the datetime column containing the invalid value - raw_value : original value that failed validation An empty DataFrame indicates that no invalid values were detected."
  },
  {
    "objectID": "reference/validate_datetime_schema.validate_datetime_schema.html#parameters",
    "href": "reference/validate_datetime_schema.validate_datetime_schema.html#parameters",
    "title": "validate_datetime_schema.validate_datetime_schema",
    "section": "",
    "text": "Name\nType\nDescription\nDefault\n\n\n\n\ndf\npandas.DataFrame\nThe DataFrame containing the datetime column(s) to validate.\nrequired\n\n\ncolumns\nlist of str\nA list of datetime column names to validate. If any specified column is not present in df, a KeyError is raised.\nrequired\n\n\ndatetime_format\nstr\nExpected datetime format string used for strict validation (e.g., ‘%Y-%m-%d’).\nrequired\n\n\ncoerce_invalid\nbool\nWhether to return a coerced copy of the DataFrame. - If False, only validation is performed and the data are not modified. - If True, valid values are converted to datetime and invalid values are set to NaT in the returned validated_df.\nFalse"
  },
  {
    "objectID": "reference/validate_datetime_schema.validate_datetime_schema.html#returns",
    "href": "reference/validate_datetime_schema.validate_datetime_schema.html#returns",
    "title": "validate_datetime_schema.validate_datetime_schema",
    "section": "",
    "text": "Name\nType\nDescription\n\n\n\n\n\ndict\nA validation summary containing: - status : {‘pass’, ‘fail’} Overall validation status across all specified columns. 'pass' indicates that no invalid values were detected; 'fail' indicates that at least one invalid value was found. - validated_df : pandas.DataFrame A copy of the input DataFrame. If coerce_invalid=True, the specified datetime columns are converted to pandas datetime dtype (with invalid values set to NaT). - invalid_records : pandas.DataFrame A tidy DataFrame listing all invalid datetime values with columns: - index : index labels from df.index where validation failed - column : name of the datetime column containing the invalid value - raw_value : original value that failed validation An empty DataFrame indicates that no invalid values were detected."
  },
  {
    "objectID": "index.html#setting-up-the-development-environment",
    "href": "index.html#setting-up-the-development-environment",
    "title": "Welcome to Datacure",
    "section": "",
    "text": "Clone the repository to your local machine by opening your terminal and run the following commands:\n\ngit clone https://github.com/UBC-MDS/DSCI_524_group20_datacure.git\ncd DSCI_524_group20_datacure\n\nCreate the conda environment from environment.yml:\n\nconda env create -f environment.yml\n\nActivate the environment:\n\nconda activate dsci_524_proj_env"
  },
  {
    "objectID": "index.html#installing-the-package",
    "href": "index.html#installing-the-package",
    "title": "Welcome to Datacure",
    "section": "",
    "text": "You can install this package into your preferred Python environment using pip:\npip install -e ."
  },
  {
    "objectID": "index.html#running-tests",
    "href": "index.html#running-tests",
    "title": "Welcome to Datacure",
    "section": "",
    "text": "You can run tests to validate all functions in the package using pytest:\npytest -v\n-v provides a verbose output showing the names of all tests and if they passed or not."
  },
  {
    "objectID": "index.html#build-documentation",
    "href": "index.html#build-documentation",
    "title": "Welcome to Datacure",
    "section": "",
    "text": "This option installs all required documentation dependencies automatically and builds the documentation:\nhatch run docs:build\n\n\n\nIf not already installed, you can install quarto from link. To generate the API reference pages and preview the documentation website run:\nquartodoc build --watch\nquarto preview"
  },
  {
    "objectID": "index.html#example-use",
    "href": "index.html#example-use",
    "title": "Welcome to Datacure",
    "section": "",
    "text": "import pandas as pd\nfrom datacure import validate_datetime_schema\n\ndf = pd.DataFrame({\n    \"program\": [\"academic\", \"general\", \"unknown\"],\n    \"start_date\": [\"2023-01-01\", \"2023-02-01\", \"01-03-2023\"]\n})\n\n# Validate datetime format\nresult = validate_datetime_schema(\n    df,\n    columns=[\"start_date\"],\n    datetime_format=\"%Y-%m-%d\"\n)"
  },
  {
    "objectID": "index.html#contributors",
    "href": "index.html#contributors",
    "title": "Welcome to Datacure",
    "section": "",
    "text": "Jose Davila\nSsemakula Peter Wasswa\nYanxin Liang\nShruti Sasi"
  },
  {
    "objectID": "index.html#copyright",
    "href": "index.html#copyright",
    "title": "Welcome to Datacure",
    "section": "",
    "text": "Copyright © 2026 Jose Davila , Ssemakula Peter Wasswa , Yanxin Liang , Shruti Sasi.\nFree software distributed under the MIT License."
  },
  {
    "objectID": "index.html#installation-for-users",
    "href": "index.html#installation-for-users",
    "title": "Welcome to Datacure",
    "section": "",
    "text": "Install the package form Test PyPI running the below command in your terminal:\npip install -i https://test.pypi.org/simple/ datacure"
  }
]